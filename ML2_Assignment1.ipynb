{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/httpsb/machine-learning/blob/main/ML2_Assignment1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torchvision import datasets\n",
        "\n",
        "trainset = datasets.MNIST(root='./data', train=True, download=True)\n",
        "testset = datasets.MNIST(root='./data', train=False, download=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iLFNkXp0dwLE",
        "outputId": "bddcad8e-8dc5-4be7-8e0e-a98a7c0c6543"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 35682221.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 1118478.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 9727826.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 4866035.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(0)\n",
        "val_ratio = 0.1\n",
        "train_size = len(trainset)\n",
        "indices = list(range(train_size))\n",
        "split_idx = int(np.floor(val_ratio * train_size))\n",
        "np.random.shuffle(indices)\n",
        "train_idx, val_idx = indices[split_idx:], indices[:split_idx]"
      ],
      "metadata": {
        "id": "Dc7FHsZZd2FY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = trainset.data[train_idx].float()/255\n",
        "train_labels = trainset.targets[train_idx]\n",
        "val_data = trainset.data[val_idx].float()/255\n",
        "val_labels = trainset.targets[val_idx]\n",
        "test_data = testset.data.float()/255\n",
        "test_labels = testset.targets"
      ],
      "metadata": {
        "id": "Au8aOxiWd5TZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('shape of train_data is ', train_data.shape)\n",
        "print('shape of train_labels is ', train_labels.shape)\n",
        "print('shape of val_data is ', val_data.shape)\n",
        "print('shape of val_labels is ', val_labels.shape)\n",
        "print('shape of test_data is ', test_data.shape)\n",
        "print('shape of test_labels is ', test_labels.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQbEvaP7lvZp",
        "outputId": "6e3eb39e-7fe7-4b86-f188-db780451eca2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape of train_data is  torch.Size([54000, 28, 28])\n",
            "shape of train_labels is  torch.Size([54000])\n",
            "shape of val_data is  torch.Size([6000, 28, 28])\n",
            "shape of val_labels is  torch.Size([6000])\n",
            "shape of test_data is  torch.Size([10000, 28, 28])\n",
            "shape of test_labels is  torch.Size([10000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#check if cuda is available\n",
        "print(torch.cuda.is_available())\n",
        "device = (\n",
        "    \"cuda\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"mps\"\n",
        "    if torch.backends.mps.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "print(f\"using {device} device\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lq8tjjW8d712",
        "outputId": "217209ba-b776-44b2-ac6e-4034461c344a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "using cuda device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#move all necessary data to GPU\n",
        "train_data = train_data.to(\"cuda\")\n",
        "train_labels = train_labels.to(\"cuda\")\n",
        "val_data = val_data.to(\"cuda\")\n",
        "val_labels = val_labels.to(\"cuda\")\n",
        "test_data = test_data.to(\"cuda\")\n",
        "test_labels = test_labels.to(\"cuda\")"
      ],
      "metadata": {
        "id": "LgOT2DgleAQN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#(a)\n",
        "\n",
        "#calculate distance\n",
        "def euclidean_distance(x1, x2):\n",
        "  return torch.sqrt(torch.sum((x1-x2)**2))\n",
        "\n",
        "def knn_predict(new_example, train_data, train_labels, k=5):\n",
        "\n",
        "  #calculate distance from new example to all training distance\n",
        "  distances = []\n",
        "  for i in range(len(train_data)):\n",
        "    distance = euclidean_distance(new_example, train_data[i])\n",
        "    distances.append((distance.item(), i))\n",
        "\n",
        "  #sort distance in ascending order and select k\n",
        "  distances.sort(key=lambda x:x[0])\n",
        "  k_nearest_neighbours = distances[:k]\n",
        "\n",
        "  #extract labels of nearest neighbors\n",
        "  k_nearest_labels = [train_labels[i] for _, i in k_nearest_neighbours]\n",
        "\n",
        "  #voting to get most common label\n",
        "  majority = torch.mode(torch.tensor(k_nearest_labels)).values\n",
        "  return majority\n"
      ],
      "metadata": {
        "id": "5kSFwCXxeEbW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "new_example = test_data[0]\n",
        "\n",
        "predicted_label = knn_predict(new_example, train_data, train_labels, k=5)\n",
        "print(f\"Predicted label: {predicted_label}\")\n",
        "\n",
        "true_label = test_labels[0]\n",
        "print(f\"True label: {true_label}\")\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"Execution time is: {end_time-start_time}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z2NhxzDEeG-8",
        "outputId": "9de7fcd1-29c4-4bde-83a2-f6d096aa0cca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted label: 7\n",
            "True label: 7\n",
            "Execution time is: 1.4906089305877686\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#(b)\n",
        "#classify a new example using knn with broadcasting\n",
        "def knn_predict_broadcast(new_example, train_data, train_labels, k=5):\n",
        "  #calculate distance\n",
        "  #euclidean dist\n",
        "  distances = torch.sqrt(torch.sum((train_data - new_example)**2, dim =(1,2)))\n",
        "\n",
        "  #get indices of k\n",
        "  k_distance, k_indices = torch.topk(distances, k, largest=False)\n",
        "\n",
        "  #get labels of k\n",
        "  k_nearest_labels = train_labels[k_indices]\n",
        "\n",
        "  #return most common class label\n",
        "  return torch.argmax(torch.bincount(k_nearest_labels))"
      ],
      "metadata": {
        "id": "9_5fvkSjeTLx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = time.time()\n",
        "\n",
        "new_example = test_data[0]\n",
        "predicted_label_broadcast = knn_predict_broadcast(new_example, train_data, train_labels, k=5)\n",
        "\n",
        "print(f\"Predicted label using broadcasting: {predicted_label_broadcast}\")\n",
        "\n",
        "true_label_broadcast = test_labels[0]\n",
        "print(f\"True label: {true_label_broadcast}\")\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"Execution time is: {end_time-start_time}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yzW-JM5ReWNN",
        "outputId": "997e4f90-b4e5-4501-ebe9-856d233e7003"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted label using broadcasting: 7\n",
            "True label: 7\n",
            "Execution time is: 0.28426146507263184\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#(c) extend from b\n",
        "#classify a new example using knn with broadcasting\n",
        "def knn_predict_c(new_example, train_data, train_labels, k=5):\n",
        "  #calculate distance\n",
        "  #euclidean dist\n",
        "  distances = torch.sqrt(torch.sum((train_data.unsqueeze(0) - new_example.unsqueeze(1))**2, dim =(2,3)))\n",
        "\n",
        "  #get indices of k\n",
        "  k_distance, k_indices = torch.topk(distances, k, largest=False)\n",
        "\n",
        "  #get labels of k\n",
        "  k_nearest_labels = train_labels[k_indices]\n",
        "\n",
        "  #return most common class label\n",
        "  return torch.argmax(torch.bincount(k_nearest_labels))"
      ],
      "metadata": {
        "id": "oShOLvyK8Ivc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_example = test_data\n",
        "pred_label_c = knn_predict_c(new_example, train_data, train_labels, k=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "id": "4t5M9oAq8Qq0",
        "outputId": "8f20927b-bf8a-4105-b98e-637ef5a8a40f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 1577.14 GiB. GPU 0 has a total capacity of 14.75 GiB of which 14.44 GiB is free. Process 9025 has 312.00 MiB memory in use. Of the allocated memory 210.53 MiB is allocated by PyTorch, and 1.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-b851f3756088>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnew_example\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpred_label_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mknn_predict_c\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_example\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-7-548f8bc3b154>\u001b[0m in \u001b[0;36mknn_predict_c\u001b[0;34m(new_example, train_data, train_labels, k)\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0;31m#calculate distance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;31m#euclidean dist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   \u001b[0mdistances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnew_example\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0;31m#get indices of k\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 1577.14 GiB. GPU 0 has a total capacity of 14.75 GiB of which 14.44 GiB is free. Process 9025 has 312.00 MiB memory in use. Of the allocated memory 210.53 MiB is allocated by PyTorch, and 1.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#question (c) and (d)\n",
        "\n",
        "def knn_predict_bybatch(test_data, train_data, train_labels, k, p, batch_size=1000):\n",
        "    all_pred = []  # To store all predictions\n",
        "    num_test_sample = test_data.shape[0]\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for start in range(0, num_test_sample, batch_size):\n",
        "            end = min(start + batch_size, num_test_sample)\n",
        "            big_chunk = test_data[start:end]\n",
        "\n",
        "            # Reshape for distance calculation\n",
        "            big_chunk_flat = big_chunk.view(-1, 28*28)   # [1000, 28*28]\n",
        "            train_data_flat = train_data.view(-1, 28*28)  # [54000, 28*28]\n",
        "\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "            # Calculate pairwise distances using torch.cdist\n",
        "            distance = torch.cdist(big_chunk_flat, train_data_flat, p=p)\n",
        "\n",
        "            # Get indices of k nearest neighbors\n",
        "            k_indices = torch.topk(distance, k, largest=False).indices\n",
        "\n",
        "            # Get labels of k nearest neighbors\n",
        "            k_nearest_labels = train_labels[k_indices]\n",
        "\n",
        "            # Return most common class label for current size\n",
        "            pred, _ = torch.mode(k_nearest_labels, dim=1) #using mode instead of bincount\n",
        "            all_pred.append(pred)  # Append to all\n",
        "\n",
        "    return torch.cat(all_pred)  # Return all predictions (concatenate into one tensor)"
      ],
      "metadata": {
        "id": "LGwGmg7ken9t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#do classification on all digits in test_data\n",
        "pred_label_batch_p2 = knn_predict_bybatch(test_data, train_data, train_labels, k=5, p=2)\n",
        "k5_p2_test_acc = (pred_label_batch_p2 == test_labels).float().mean()\n",
        "print(f\"test accuracy when k=5 and p=2 is: {k5_p2_test_acc*100:.2f}% \")\n",
        "\n",
        "pred_label_val = knn_predict_bybatch(val_data, train_data, train_labels, k=5, p=2)\n",
        "k5_p2_val_acc = (pred_label_val == val_labels).float().mean()\n",
        "print(f'val accuracy when k=5 and p=2 is {k5_p2_val_acc*100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9tHn-pwxe6Ji",
        "outputId": "fea472ea-d1dd-4b74-bb7d-b214984d8f86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test accuracy when k=5 and p=2 is: 96.65% \n",
            "val accuracy when k=5 and p=2 is 97.37%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "size_arr = [5, 10, 15, 50, 100, 1000]\n",
        "\n",
        "for n in size_arr:\n",
        "  pred_label_batch = knn_predict_bybatch(val_data, train_data, train_labels, k=5, p=2, batch_size=n)\n",
        "  val_accuracy = (pred_label_batch == val_labels).float().mean()\n",
        "  print(f'Validation accuracy for batch_size {n}: {val_accuracy.item() * 100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rK2r80vIg04m",
        "outputId": "11b4a5bd-4129-408a-877d-df8a03585991"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation accuracy for batch_size 5: 97.37%\n",
            "Validation accuracy for batch_size 10: 97.37%\n",
            "Validation accuracy for batch_size 15: 97.37%\n",
            "Validation accuracy for batch_size 50: 97.37%\n",
            "Validation accuracy for batch_size 100: 97.37%\n",
            "Validation accuracy for batch_size 1000: 97.37%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since batch size doesnt seem to improve accuracy, we can try tuning other hyperparameter. In this case, I chose distance calculation.\n"
      ],
      "metadata": {
        "id": "tT_91EO_hUNK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#now check for best values of k and which distance calculation is the best, euclidean or manhattan\n",
        "arr_k = [1,3,5,10,13,18]\n",
        "p_arr = [1,2]\n",
        "val_acc = []\n",
        "best_acc = 0\n",
        "best_k = None\n",
        "best_p = None\n",
        "\n",
        "for k in arr_k:\n",
        "    for p in p_arr:\n",
        "        pred_label_batch = knn_predict_bybatch(val_data, train_data, train_labels, k, p)\n",
        "        val_accuracy = (pred_label_batch == val_labels).float().mean()\n",
        "        print(f'Validation accuracy for k={k}, p: {p}: {val_accuracy.item() * 100:.2f}%')\n",
        "        val_acc.append(val_accuracy.item())\n",
        "\n",
        "        if best_acc < val_accuracy.item():\n",
        "          best_acc = val_accuracy.item()\n",
        "          best_k = k\n",
        "          best_p = p\n",
        "\n",
        "print(f\"Best accuracy is {best_acc*100:.2f}% where the values of k is {best_k} and p is {best_p}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qnA6EFRxfKWX",
        "outputId": "3428d58f-fc57-4c3e-ee15-c3dd87cd2657"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation accuracy for k=1, p: 1: 96.77%\n",
            "Validation accuracy for k=1, p: 2: 97.47%\n",
            "Validation accuracy for k=3, p: 1: 96.93%\n",
            "Validation accuracy for k=3, p: 2: 97.55%\n",
            "Validation accuracy for k=5, p: 1: 96.55%\n",
            "Validation accuracy for k=5, p: 2: 97.37%\n",
            "Validation accuracy for k=10, p: 1: 96.50%\n",
            "Validation accuracy for k=10, p: 2: 97.17%\n",
            "Validation accuracy for k=13, p: 1: 96.23%\n",
            "Validation accuracy for k=13, p: 2: 96.88%\n",
            "Validation accuracy for k=18, p: 1: 96.10%\n",
            "Validation accuracy for k=18, p: 2: 96.75%\n",
            "Best accuracy is 97.55% where the values of k is 3 and p is 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#val data accuracy\n",
        "pred_label_batch_val = knn_predict_bybatch(val_data, train_data, train_labels, k=3, p=2)\n",
        "\n",
        "val_accuracy = (pred_label_batch_val == val_labels).float().mean()\n",
        "print(f'val test accuracy: {val_accuracy.item() * 100:.2f}%')#do classification on all digits in test_data\n",
        "pred_label_batch_test = knn_predict_bybatch(test_data, train_data, train_labels, k=3, p=2)\n",
        "\n",
        "#final test accuracy\n",
        "pred_label_batch_test = knn_predict_bybatch(test_data, train_data, train_labels, k=3, p=2)\n",
        "\n",
        "test_accuracy = (pred_label_batch_test == test_labels).float().mean()\n",
        "print(f'test accuracy: {test_accuracy.item() * 100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ngPAKBlfTai",
        "outputId": "2c5ac911-b3e9-4f40-e02f-d5973bcb67ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val test accuracy: 97.55%\n",
            "test accuracy: 96.97%\n"
          ]
        }
      ]
    }
  ]
}